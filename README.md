# ğŸ§  Employee Leave Assistant

An AI-powered assistant that intelligently answers employee leave-related queries by parsing HR documents like employee records (CSV/JSON) and leave policy documents (PDF). Built with **FastAPI**, **React**, and integrated with **local or cloud LLMs** (e.g., via Ollama or Hugging Face), it serves as a smart backend system for HR automation.

---

## ğŸš€ Features

- ğŸ” **Natural Language Q&A** over structured (employee CSV) and unstructured (PDF) documents
- ğŸ“‚ **Multi-file parsing** (CSV/JSON + PDF)
- ğŸ§  **LLM Integration** (via Ollama or cloud API)
- ğŸ§‘â€ğŸ’¼ **Employee-specific answers** using filters like name or ID
- ğŸ’¡ **Frontend** in React with live interaction
- âš™ï¸ **FastAPI backend** for robust REST API support
- ğŸ”’ 100% local model execution supported with **Ollama**

---


---

## ğŸ”§ Tech Stack

| Layer | Tech |
|-------|------|
| ğŸ§  LLM | [Ollama](https://ollama.com/), [Mistral](https://mistral.ai/), [Phi-3](https://huggingface.co/microsoft/phi-3-mini-128k) |
| âš™ï¸ Backend | FastAPI, PyMuPDF (PDF parsing), Pandas |
| ğŸ’» Frontend | React, Axios |
| ğŸ“š Optional Tools | LangChain, LlamaIndex (for advanced context retrieval) |

---

## ğŸ“Œ How It Works

1. User uploads employee records (CSV/JSON) and company policy (PDF)
2. The backend parses these documents and extracts relevant information
3. The user selects an employee and asks a natural language question
4. The backend:
   - Retrieves relevant context from the data
   - Sends it as a prompt to the local/cloud LLM
   - Returns a generated answer to the frontend

---

## âš™ï¸ Installation

### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload

